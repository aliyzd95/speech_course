{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework (15 points)\n",
    "\n",
    "In this homework we train Sound Event Detection model.\n",
    "\n",
    "Dataset: https://disk.yandex.ru/d/NRpDIp4jg2ODqg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import tqdm.notebook as tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as torch_data\n",
    "import torchaudio\n",
    "import urllib\n",
    "\n",
    "# implementation of Dataset for given data|\n",
    "import dataset\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "from io import BytesIO\n",
    "from tarfile import TarFile\n",
    "import tarfile\n",
    "\n",
    "base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?'\n",
    "public_key = 'https://disk.yandex.ru/d/NRpDIp4jg2ODqg'\n",
    "dst_path = '/home/jupyter/mnt/datasets/sound_event_detection/dataset/' # if we make the Datasphere datasets work\n",
    "dst_path = './dataset/'\n",
    "\n",
    "final_url = base_url + urlencode(dict(public_key=public_key))\n",
    "response = requests.get(final_url)\n",
    "download_url = response.json()['href']\n",
    "\n",
    "# if you aren't in the Datasphere\n",
    "# !wget -O data.tar.gz  \"{download_url}\"\n",
    "# !tar -xf data.tar.gz \n",
    "\n",
    "# otherwise\n",
    "# response = requests.get(download_url)\n",
    "# io_bytes = BytesIO(response.content)\n",
    "# tar = tarfile.open(fileobj=io_bytes, mode='r:gz')\n",
    "# tar.extractall(path=dst_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' # also you can use \"cuda\" for gpu and \"mps\" for apple silicon\n",
    "DATADIR = dst_path + 'data'\n",
    "LOADER_WORKERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FBANK 80 by default, but you can choose something else\n",
    "FEATS = 80\n",
    "transform_train = nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(n_mels=FEATS),\n",
    "    # torchaudio.transforms.AmplitudeToDB(),\n",
    "    # augmentation(1)\n",
    ")\n",
    "transform_test = nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(n_mels=FEATS),\n",
    "    # torchaudio.transforms.AmplitudeToDB()\n",
    ")\n",
    "trainset = dataset.Dataset('train', DATADIR, transform_train)\n",
    "testset = dataset.Dataset('eval', DATADIR, transform_test)\n",
    "N_CLASSES = trainset.classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval part (1 point)\n",
    "\n",
    "Write balanced accuracy:\n",
    "$$BAcc = \\frac{1}{classes}\\sum_{c = 1}^{classes} \\frac{\\sum_i^n I(y_i = p_i = c)}{\\sum_i^n I(y_i = c)}$$\n",
    "\n",
    "Where:\n",
    "- $y_i$ -- target class for $i$ element\n",
    "- $p_i$ -- predicted class for $i$ element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-02-17T13:47:04.762187598Z",
     "iopub.status.idle": "2025-02-17T13:47:04.765667599Z",
     "shell.execute_reply": "2025-02-17T13:47:04.762175878Z"
    }
   },
   "outputs": [
    {
     "ename": "Unknown instance spec",
     "evalue": "Please select VM configuration",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# Get list of pairs (target_class, predicted_class)\n",
    "from collections import defaultdict\n",
    "def balanced_accuracy(items: list[tuple[int, int]]) -> float:\n",
    "    result = 0\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(balanced_accuracy([(0, 0), (0, 0), (1, 1)]), 1.0)\n",
    "assert np.isclose(balanced_accuracy([(0, 1), (1, 0)]), 0.0)\n",
    "assert np.isclose(balanced_accuracy([(0, 0), (0, 0), (1, 0)]), 0.5)\n",
    "assert np.isclose(balanced_accuracy([(0, 0), (1, 1), (0, 0), (0, 0), (1, 0), (0, 1)]), 0.625)\n",
    "assert np.isclose(balanced_accuracy([(1, 1), (0, 1), (2, 2)]), 0.66666666666666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train part (14 points)\n",
    "\n",
    "Train some model with test accuracy > 0.5\n",
    "\n",
    "You can train any model you want. The only limitations are \n",
    "    1) it must be trained from scratch on the data provided in the task\n",
    "    2) it must have less than 5M parameters\n",
    "\n",
    "For example you can choose model from:\n",
    "- DNN\n",
    "- CNN 1d\n",
    "- CNN 2d\n",
    "- Transformer\n",
    "- RNN\n",
    "- mixes of given models\n",
    "\n",
    "You can draw inspiration from the big models and build your own small model from scratch.\n",
    "\n",
    "Hints:\n",
    "- No need to train large models for this task. 5 million parameters is much more than you need.\n",
    "- The score can be achieved by models with less than 100K params\n",
    "- Take the feature dimension into account\n",
    "- Monitor overfitting, try to add Augmentation, Dropout, BatchNorm, L1/L2-Regulatization or something else.\n",
    "- Score of 0.35 is easily achievable by CNN 1d\n",
    "- Use poolings or strides to reduce time-dimenstion. It is better to reduce the dimension gradually rather than at the end.\n",
    "- Pay attention to the time dimension at the end of the network. How big is the receptive field of the network?\n",
    "- Try different features (mel-spec, log-mel-spec, mfcc)\n",
    "- You may need more than 10 epochs. One would would consider 20-30 epochs as a reasonable estimate\n",
    "- You may need to use smaller batches)\n",
    "\n",
    "P.S. Points can be subtracted for unclear training charts. Keep all the experiments that you've run in the notebook.\n",
    "\n",
    "PP.S. It is sufficient for your model to beat the threshold once. We imagine a) there is a hidden best checkpoint save option and b) that the distribution of the test used to monitor the training is identical to the distribution of all possible tests)\n",
    "\n",
    "PPP.S. A partial score will be awarded for a test accuracy < 0.5. Score of 0.35 is easily achievable by CNN 1d\n",
    "\n",
    "PPPP.S. Add log to Melspectrogram in torchaudio.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_params(model):\n",
    "    result = 0\n",
    "    for param in model.parameters():\n",
    "        result += param.numel()\n",
    "    return result\n",
    "\n",
    "\n",
    "def stage(\n",
    "    model: nn.Module,\n",
    "    data: dataset.Dataset,\n",
    "    opt: optim.Optimizer,\n",
    "    batch_size: int = 256,\n",
    "    train: bool = True\n",
    "):\n",
    "    loader = torch_data.DataLoader(\n",
    "        data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=LOADER_WORKERS,\n",
    "        collate_fn=dataset.collate_fn\n",
    "    )\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    loss_sum, batches = 0.0, 0\n",
    "    pred_pairs = []\n",
    "    for X, Y in tqdm.tqdm(loader):\n",
    "        pred = model.forward(X.to(DEVICE))\n",
    "        loss = F.cross_entropy(pred.squeeze(), Y.squeeze().to(DEVICE))\n",
    "        if train:\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        loss_sum += loss.item()\n",
    "        batches += 1\n",
    "        with torch.no_grad():\n",
    "            pred_pairs.extend(zip(\n",
    "                Y.data.numpy().reshape(-1),\n",
    "                torch.argmax(pred, dim=1).cpu().data.numpy().reshape(-1)\n",
    "            ))\n",
    "    return loss_sum / batches, balanced_accuracy(pred_pairs)\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    opt,\n",
    "    batch_size: int = 256,\n",
    "    epochs: int = 10,\n",
    "):\n",
    "    train_losses, test_losses, train_accs, test_accs = [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = stage(model, trainset, opt, batch_size=batch_size)\n",
    "        test_loss, test_acc = stage(model, testset, opt, batch_size=batch_size, train=False)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "        clear_output()\n",
    "        fig, axis = plt.subplots(1, 2, figsize=(15, 7))\n",
    "        axis[0].plot(np.arange(1, epoch + 2), train_losses, label='train')\n",
    "        axis[0].plot(np.arange(1, epoch + 2), test_losses, label='test')\n",
    "        axis[1].plot(np.arange(1, epoch + 2), train_accs, label='train')\n",
    "        axis[1].plot(np.arange(1, epoch + 2), test_accs, label='test')\n",
    "        axis[0].set(xlabel='epoch', ylabel='CE Loss')\n",
    "        axis[1].set(xlabel='epoch', ylabel='Accuracy')\n",
    "        fig.legend()\n",
    "        plt.show()\n",
    "        print(f'Epoch {epoch + 1}.')\n",
    "        print(f'Train loss {train_loss}. Train accuracy {train_acc}.')\n",
    "        print(f'Test loss {test_loss}. Test accuracy {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseSeparable(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padidng=0):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            ???\n",
    "        )\n",
    "        self.pointwise = nn.Conv2d(???)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.pointwise(self.depthwise(X))\n",
    "    \n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_dim=FEATS, out_dim=N_CLASSES):\n",
    "        super().__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            # <YOUR CODE IS HERE>\n",
    "        )\n",
    "        \n",
    "       \n",
    "    def forward(self, X):\n",
    "        # input: [batch_size, IN_FEATURES, TIME]\n",
    "        # output: [batch_size, N_CLASSES]\n",
    "        # <YOUR CODE IS HERE>\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(DEVICE)\n",
    "print(\"Number of parameters is \", get_number_of_parameters(model))\n",
    "opt = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
